{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Amruta Rajopadhye <br />\n",
    "Kaggle Username: wingjammer1993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import nltk\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def stem_pos_sentences(examples):\n",
    "    new_examples = []\n",
    "    new_pos = []\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmer = WordNetLemmatizer()\n",
    "    for ex in examples:\n",
    "        gen_list = word_tokenize(ex)\n",
    "        pos = nltk.pos_tag(gen_list)\n",
    "        pos = [p[-1] for p in pos if p[-1]]\n",
    "        lemms = [lemmer.lemmatize(ex) for ex in gen_list]\n",
    "        singles = [stemmer.stem(ex) for ex in lemms]\n",
    "        new_examples.append(' '.join(singles))\n",
    "        new_pos.append(' '.join(pos))\n",
    "    return new_examples, new_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatEngr:\n",
    "    def __init__(self):\n",
    "        \n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        \n",
    "        self.vectorizer = TfidfVectorizer(ngram_range=(1,2), stop_words= {'English'})\n",
    "        self.tag_vectorizer = CountVectorizer()\n",
    "\n",
    "    def build_train_features(self, examples):\n",
    "        \"\"\"\n",
    "        Method to take in training text features and do further feature engineering \n",
    "        Most of the work in this homework will go here, or in similar functions  \n",
    "        :param examples: currently just a list of forum posts  \n",
    "        \"\"\"\n",
    "\n",
    "        import scipy as sp\n",
    "        from scipy.sparse import csr_matrix\n",
    "        \n",
    "        stemmed_sentences, tags = stem_pos_sentences(list(examples[\"sentence\"]))\n",
    "        feature_1 = self.vectorizer.fit_transform(stemmed_sentences)\n",
    "        feature_2 = self.tag_vectorizer.fit_transform(tags)\n",
    "        training_vec = sp.sparse.hstack((feature_1, feature_2))\n",
    "        return training_vec\n",
    "\n",
    "    def get_test_features(self, examples):\n",
    "        \"\"\"\n",
    "        Method to take in test text features and transform the same way as train features \n",
    "        :param examples: currently just a list of forum posts  \n",
    "        \"\"\"\n",
    "        import scipy as sp\n",
    "        from scipy.sparse import csr_matrix     \n",
    "\n",
    "        stemmed_sentences, tags = stem_pos_sentences(list(examples[\"sentence\"]))\n",
    "        feature_1 = self.vectorizer.transform(stemmed_sentences)\n",
    "        feature_2 = self.tag_vectorizer.transform(tags)\n",
    "        test_vec = sp.sparse.hstack((feature_1, feature_2))\n",
    "        return test_vec  \n",
    "\n",
    "\n",
    "    def show_top10(self):\n",
    "        \"\"\"\n",
    "        prints the top 10 features for the positive class and the \n",
    "        top 10 features for the negative class. \n",
    "        \"\"\"\n",
    "        feature_names = np.asarray(self.vectorizer.get_feature_names())\n",
    "        top10 = np.argsort(self.logreg.coef_[0])[-10:]\n",
    "        bottom10 = np.argsort(self.logreg.coef_[0])[:10]\n",
    "        print(\"Pos: %s\" % \" \".join(feature_names[top10]))\n",
    "        print(\"Neg: %s\" % \" \".join(feature_names[bottom10]))\n",
    "                \n",
    "    def train_model(self, random_state=1234):\n",
    "        \"\"\"\n",
    "        Method to read in training data from file, and \n",
    "        train Logistic Regression classifier. \n",
    "        \n",
    "        :param random_state: seed for random number generator \n",
    "        \"\"\"\n",
    "        \n",
    "        from sklearn.linear_model import LogisticRegression \n",
    "        \n",
    "        # load data \n",
    "        dfTrain = pd.read_csv(\"train.csv\")\n",
    "        \n",
    "        # get training features and labels \n",
    "        self.X_train = self.build_train_features(dfTrain)\n",
    "        self.y_train = np.array(dfTrain[\"spoiler\"], dtype=int)\n",
    "        \n",
    "        # train logistic regression model.  !!You MAY NOT CHANGE THIS!! \n",
    "        self.logreg = LogisticRegression(random_state=random_state)\n",
    "        self.logreg.fit(self.X_train, self.y_train)\n",
    "        \n",
    "    def model_predict(self):\n",
    "        \"\"\"\n",
    "        Method to read in test data from file, make predictions\n",
    "        using trained model, and dump results to file \n",
    "        \"\"\"\n",
    "        \n",
    "        # read in test data \n",
    "        dfTest  = pd.read_csv(\"test.csv\")\n",
    "        \n",
    "        # featurize test data \n",
    "        self.X_test = self.get_test_features(dfTest)\n",
    "        \n",
    "        # make predictions on test data \n",
    "        pred = self.logreg.predict(self.X_test)\n",
    "        \n",
    "        # dump predictions to file for submission to Kaggle  \n",
    "        pd.DataFrame({\"spoiler\": np.array(pred, dtype=bool)}).to_csv(\"prediction.csv\", index=True, index_label=\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the FeatEngr clas \n",
    "feat = FeatEngr()\n",
    "\n",
    "# Train your Logistic Regression classifier \n",
    "feat.train_model(random_state=1230)\n",
    "\n",
    "# Make prediction on test data and produce Kaggle submission file \n",
    "feat.model_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
